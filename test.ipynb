{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import emailProcessing\n",
    "with open('RawEmails.json', 'r') as file:\n",
    "    datas = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(message):\n",
    "    output = re.sub(r'[\\u200b\\u200c\\u200d\\u200e\\u200f\\ufeff\\r\\xa0\\ud83d\\ude80\\u202f\\u2019\\u2014\\u2605\\u2022\\u2023\\u2024\\u034f]', '', BeautifulSoup(message, \"lxml\").text)\n",
    "    return outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "def emailProcessing(emails):\n",
    "    \"\"\"\n",
    "    Take a list of raw emails, and process them into a dictionary where sender email is the key and a list of tuples containing the email id, labelIds, snippet, and internalDate is the value.\n",
    "    \"\"\"\n",
    "    senders = defaultdict(list)\n",
    "    \n",
    "    for sender in emails:\n",
    "        for s_sender in sender[\"payload\"][\"headers\"]:\n",
    "            if \"From\" in s_sender[\"name\"]:\n",
    "                headers = sender.get('payload', {}).get('headers', [])\n",
    "                for header in headers:\n",
    "                    if header.get('name', '').lower() == 'subject':\n",
    "                        title = header.get('value', 'No title found')\n",
    "                if \"data\" in sender[\"payload\"][\"body\"]:\n",
    "                    decoder = base64.urlsafe_b64decode(sender[\"payload\"][\"body\"][\"data\"].encode(\"ASCII\")).decode(\"utf-8\")\n",
    "                    senders[s_sender[\"value\"]].append((sender[\"id\"], sender[\"labelIds\"], title, decoder, sender[\"internalDate\"]))\n",
    "                elif \"data\" in sender[\"payload\"][\"parts\"][0][\"body\"]:\n",
    "                    decoder = base64.urlsafe_b64decode(sender[\"payload\"][\"parts\"][0][\"body\"][\"data\"].encode(\"ASCII\")).decode(\"utf-8\")\n",
    "                    senders[s_sender[\"value\"]].append((sender[\"id\"], sender[\"labelIds\"], title, decoder, sender[\"internalDate\"]))\n",
    "    \n",
    "    return senders\n",
    "sll = emailProcessing(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "from transformers import pipeline\n",
    "from collections import defaultdict\n",
    "from subprocess import list2cmdline\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "model_checkpoint = \"xlm-roberta-large-finetuned-conll03-english\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "def org_name(extracted_text):\n",
    "    # Extract the complete text in the resume\n",
    "    classifier = token_classifier(extracted_text)\n",
    "    entity_name = None\n",
    "    max_score = 0\n",
    "    for s in classifier:\n",
    "        if s['entity_group'] == 'ORG':\n",
    "            if s['score'] > max_score:\n",
    "                entity_name = s['word']\n",
    "                max_score = s['score']\n",
    "    return entity_name\n",
    "\n",
    "\n",
    "def application_categorizer(content):\n",
    "    \"\"\"\n",
    "    Take a dictionary of emails grouped by sender, with id, labelIds, content, internalDate as the value.\n",
    "    Return a dictionary with two keys: \"app_focused\" and \"non_app_focused\".\n",
    "    \"app_focused\" key will point to a dictionary of emails that are application related, with company emails as the key and a list of tuples containing the email id, labelIds, snippet, and internalDate as the value.\n",
    "    \"non_app_focused\" key will point to a dictionary of emails that are not application related, with company emails as the key and a list of tuples containing the email id, labelIds, snippet, and internalDate as the value.\n",
    "    \"\"\"\n",
    "    application = defaultdict(list)\n",
    "    non_application = defaultdict(list)\n",
    "    combine_list = defaultdict(list)\n",
    "    for company, email_data in content.items():\n",
    "        for mailId, mailCategories, mailSubject, mailContent, mailTime in email_data:\n",
    "            newMailContent = clean_text(mailContent)   \n",
    "            newMailTime = datetime.datetime.fromtimestamp(int(mailTime)/1e3)\n",
    "            if (\"CATEGORY_PERSONAL\" in mailCategories or \"CATEGORY_UPDATES\" in mailCategories or \"IMPORTANT\" in mailCategories) and (\"great fit\" not in mailSubject.lower() or \n",
    "                                                                                                        \"apply now\" not in mailSubject.lower()):\n",
    "                if any(keyword in mailSubject.lower() or keyword in newMailContent.lower() for keyword in \n",
    "                       [\"application\", \"applications\", \"assessment\", \"assessments\", \n",
    "                        \"next step\", \"submission\", \"submissions\", \"recruiting\"]):\n",
    "                    application[company].append([mailId, mailCategories, mailSubject, newMailContent, str(newMailTime)])\n",
    "            else:\n",
    "                non_application[company].append([mailId, mailCategories, mailSubject, newMailContent, str(newMailTime)])\n",
    "\n",
    "    \n",
    "    #Move unnecessary emails from application list non-application list\n",
    "    temp_list_non_app = [company for company in non_application.keys()]\n",
    "    for i in temp_list_non_app:\n",
    "        if i in application.keys():\n",
    "            non_application[i] = application[i]\n",
    "            del application[i]\n",
    "    combine_list[\"app_focused\"] = application\n",
    "    combine_list[\"non_app_focused\"] = non_application\n",
    "    \n",
    "    return combine_list\n",
    "\n",
    "def gimmeAFunctionName(file):\n",
    "    app_focused = file['app_focused']\n",
    "    \n",
    "    the_fix = defaultdict(list)\n",
    "    \n",
    "    for email, content in app_focused.items():\n",
    "        for mailId, mailCategories, mailSubject, mailContent, mailTime in content:\n",
    "            mailCorporationName = org_name(mailContent)\n",
    "            \n",
    "            # If no company name is found, use the original email address\n",
    "            if mailCorporationName is None:\n",
    "                mailCorporationName = email\n",
    "            \n",
    "            # Add the email data under the company name\n",
    "            the_fix[mailCorporationName].append([mailId, mailCategories, mailSubject, mailContent, mailTime])\n",
    "    # Replace the original 'app_focused' content with the merged version\n",
    "    file['app_focused'] = the_fix\n",
    "    \n",
    "    return file\n",
    "    \n",
    "\n",
    "ssssss = gimmeAFunctionName(application_categorizer(sll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resulttt2.json', 'w') as f:\n",
    "    json.dump(ssssss, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x = \"\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nDear Tri Cuong,\\nThank you for the time and energy you invested in applying for the position Intern: Data Analyst (Summer 2024) (5165).\\n\\n\\t\\t\\t\\t\\t\\tUnfortunately, we have to inform you that this time we have decided to move on with other candidates.\\n\\n\\t\\t\\t\\t\\t\\tWe appreciate your interest in our company and are grateful for the opportunity to get to know you and your aspirations.\\n\\n\\t\\t\\t\\t\\t\\tWe greatly value your interest for shaping the future of transport solutions together with us.\\n\\t\\t\\t\\t\\t\\tWe hope you will keep us in mind and apply again for future positions within your areas of expertise.\\n\\n\\t\\t\\t\\t\\t\\tUntil then, we wish you all the best in your future career. Once again, thank you for your interest in working with Volvo Group.\\n\\n\\n\\t\\t\\t\\t\\t\\tBest regards,\\n\\t\\t\\t\\t\\t\\tVolvo Group Talent Acquisition\\n\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\nABOUT US | YOUR CAREER AT VOLVO GROUP | MEET OUR EMPLOYEES | FOLLOW US ON SOCIAL MEDIA\\n\\n\\n\\n\\n\\n\\n\\n\\n\"\n",
    "\n",
    "if \"great fit\" in x:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for a,b in ssssss['non_app_focused'].items():\n",
    "    for i in b:\n",
    "        contents.append(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resulttt2.json', 'w') as f:\n",
    "    json.dump(ssssss, f, indent=4)\n",
    "\n",
    "with open('content_emails_non_app.json', 'w') as f:\n",
    "    json.dump(contents, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "f = ['this is my text', 'what', 'the', 'heck']\n",
    "\n",
    "for i in f:\n",
    "    if 'is' in i:\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'categorizer3.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorizer3.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     datas \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'categorizer3.json'"
     ]
    }
   ],
   "source": [
    "with open('categorizer3.json', 'r') as file:\n",
    "    datas = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m key_list \u001b[38;5;241m=\u001b[39m defaultdict()\n\u001b[0;32m----> 3\u001b[0m daaaa \u001b[38;5;241m=\u001b[39m \u001b[43mdatas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnon_app_focused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m countdaaa \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, email \u001b[38;5;129;01min\u001b[39;00m daaaa\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "key_list = defaultdict()\n",
    "daaaa = datas[\"non_app_focused\"]\n",
    "countdaaa = 0\n",
    "for i, email in daaaa.items():\n",
    "    countdaaa += len(email)\n",
    "countdaaa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countdaaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcountdaaa\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countdaaa' is not defined"
     ]
    }
   ],
   "source": [
    "countdaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.49425287356321"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsePositiveList = ['The Untapped Team <marketing@untapped.io>', 'Google <no-reply@accounts.google.com>', 'Paisly by JetBlue <jetblueairways@email.jetblue.com>', \n",
    "                 'Capital One <donotreply@bankmessage.capitalone.com>', 'JetBlue <jetblueairways@email.jetblue.com>', 'Progressive <customerservice@e.progressive.com>',\n",
    "                 'Eric <eric@jobrightai.com>', '\\\"Abby F.\\\" <info@bb3.wayup.com>', 'qorvousinc-jobnotification@noreply.jobs2web.com', 'Temu <email@market.temuemail.com>',\n",
    "                 'Shopee <info@mail.shopee.vn>', 'Indeed <donotreply@indeed.com>', 'support@referralhub.dev', 'Tata Consultancy Services via WayUp <info@wayup.com>',\n",
    "                 'Indeed <no-reply@indeed.com>', 'LinkedIn <jobs-noreply@linkedin.com>', '\\\"Peter Mattis @ Cockroach Labs\\\" <news@mail.cockroachlabs.com>',\n",
    "                 'Recruiter via WayUp <info@bb3.wayup.com>', 'Spotify <no-reply@spotify.com>', 'Twilio <no-reply@twilio.com>', 'Sapna B <sapna.b@brilliantinfotech.com>',\n",
    "                 '\\\"Freelancer.com\\\" <noreply@notifications.freelancer.com>', 'Michael Yan <michael@hey.simplify.jobs>', 'Simplify Team <noreply@simplify.jobs>', 'Apple <no_reply@email.apple.com>',\n",
    "                 'Hiring at Intuit <hiring@intuit.com>', 'Spirit Airlines <booking@fly.spirit-airlines.com>', 'Glassdoor Community <info@glassdoor.com>', 'Free Spirit <FreeSpirit@fly.spirit-airlines.com>',\n",
    "                 'China Airlines <calmarketing@email-china-airlines.com>', 'Recruiter via WayUp <recruiter.2.2131160214@messages.wayup.com>', 'True', 'Zety <info@tr.zety.com>', 'Hosted', '\\\"Phil @ ZipRecruiter\\\" <phil@ziprecruiter.com>',\n",
    "                 'ZipRecruiter <support@ziprecruiter.com>', 'membership@governmentjobs.com', 'jobnotification@avaturecrm.com', 'Coursera <no-reply@m.mail.coursera.org>']\n",
    "truePositive = 386\n",
    "falseNegative = 141\n",
    "trueNegative = 517\n",
    "falsePositive = 0\n",
    "\n",
    "Accuracy = (truePositive + trueNegative)/(truePositive + trueNegative + falsePositive + falseNegative)\n",
    "Accuracy *= 100\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i, email in daaaa.items():\n",
    "    if i in falsePositiveList:\n",
    "        count += len(email)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.9998582, 'word': 'Tri Cuong', 'start': 3, 'end': 12}, {'entity_group': 'ORG', 'score': 0.9999771, 'word': 'Akuna Capital', 'start': 44, 'end': 57}, {'entity_group': 'MISC', 'score': 0.9988606, 'word': 'Python', 'start': 128, 'end': 134}, {'entity_group': 'LOC', 'score': 0.9999567, 'word': 'Chicago', 'start': 969, 'end': 976}, {'entity_group': 'ORG', 'score': 0.9943621, 'word': 'akunacapital', 'start': 1031, 'end': 1043}, {'entity_group': 'MISC', 'score': 0.99302113, 'word': 'Options 101', 'start': 1166, 'end': 1177}, {'entity_group': 'ORG', 'score': 0.97176725, 'word': 'akunacapital', 'start': 1188, 'end': 1200}, {'entity_group': 'ORG', 'score': 0.9873828, 'word': 'akunacapital', 'start': 1273, 'end': 1285}, {'entity_group': 'ORG', 'score': 0.9762569, 'word': 'akunacapital', 'start': 1328, 'end': 1340}, {'entity_group': 'ORG', 'score': 0.87209845, 'word': 'Akuna Capital Recruitment Team', 'start': 1392, 'end': 1422}, {'entity_group': 'ORG', 'score': 0.99772835, 'word': 'akunacapital', 'start': 1426, 'end': 1438}, {'entity_group': 'ORG', 'score': 0.9938626, 'word': 'akunacapital', 'start': 1456, 'end': 1468}, {'entity_group': 'ORG', 'score': 0.74108595, 'word': 'com', 'start': 1469, 'end': 1472}]\n",
      "The time of execution of above program is : 3.82\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from subprocess import list2cmdline\n",
    "from pdfminer.high_level import extract_text\n",
    "import docx2txt\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import time\n",
    "start = time.time()\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "model_checkpoint = \"xlm-roberta-large-finetuned-conll03-english\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Organisation names extraction\n",
    "def org_name(file):\n",
    "    # Extract the complete text in the resume\n",
    "    extracted_text = file\n",
    "    classifier = token_classifier(extracted_text)\n",
    "    entity_name = None\n",
    "    max_score = 0\n",
    "    # for s in classifier:\n",
    "    #     if s['entity_group'] == 'ORG':\n",
    "    #         if s['score'] > max_score:\n",
    "    #             entity_name = s['word']\n",
    "    #             max_score = s['score']\n",
    "    print(classifier)\n",
    "\n",
    "       \n",
    "org_name(\"Hi Tri Cuong,Thank you for your interest in Akuna Capital! We have received your application for the Software Engineer Intern - Python, Summer 2025 role and we look forward to reviewing your application. Please note that due to the large quantity of applicants we've received for this role, there have been significant lags in the process. We will still be accepting applications, but wanted to inform you of any potential delays. If your qualifications align with our needs for this particular role, a member of our recruitment team will be in touch with you to coordinate next steps.Please be sure to keep an eye on your spam/junk folder for any communications from us or our testing partners. If you move forward in the interview process with us, please know that all interview questions are confidential and not to be shared externally.In the meantime, please check out some of the links below to get to know us better:* Meet a few members of our team and tour our Chicago headquarters through our virtual reality ( https://vr.akunacapital.com/registration/ ) experience.* Explore ( https://youtu.be/oAS29_yxVcc ) the world of options market making and take our Options 101 ( https://akunacapital.teachable.com/ ) course.* Learn more about our hiring process ( https://akunacapital.com/careers#hire-dev ) and FAQs ( https://akunacapital.com/careers#general ) from candidates.Kind regards,Akuna Capital Recruitment Teamwww.akunacapital.com ( http://www.akunacapital.com )**Please note: Do not reply to this email. This email is sent from an unattended mailbox. Replies will not be read.\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"The time of execution of above program is :\", round((end - start), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;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_cmVmPWVtYWlsJnV0bV9zb3VyY2U9V2hhdG5vdCZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9jYW1wYWlnbj1hdHNfaW52aXRlX2Zyb21fb3JnYW5pemF0aW9uJnV0bV9jb250ZW50PWN0YWJ1dHRvbiZlbWFpbD1zdGVwaGVubHVvbmcyNCU0MGdtYWlsLmNvbSZhdHNfYWNjb3VudF9saW5rX3Rva2VuPTljU2JSQTJmMFR2UXdtaHhOVVdBY2JETFE4Q29YWlRuJnN0dWRlbnRfZnVsbF9uYW1lPVRyaStDdW9uZytMdW9uZyZsb2dvX3VybD1odHRwcyUzQSUyRiUyRmp1bXBzdGFydC1zdGF0aWMuczMuYW1hem9uYXdzLmNvbSUyRmJhY2tlbmQlMkZfX3NpemVkX18lMkZvcmdhbml6YXRpb25zJTJGb3JnYW5pemF0aW9uJTJGel8wdjdiOEhTM3F5NHIxY2VMRGVFUS10aHVtYm5haWwtMjAweDIwMC5wbmcmb3JnYW5pemF0aW9uX2lkPXdoYXRub3Qmb3JnYW5pemF0aW9uX25hbWU9V2hhdG5vdCZyb2xlX2lkPTM2YjE1NzQwLThlZTItNGZiMi05MGZiLTc1NWU5YTBjMGI0MCZyb2xlX3R5cGU9Sk9CJnJvbGVfdGl0bGU9U29mdHdhcmUrRW5naW5lZXIrSW50ZXJuJTJDK1N1bW1lcisyMDI1KQ0KDQpGQVE6IFdoYXQgZWxzZSBkbyBJIGdldCBmcm9tIFVudGFwcGVkP8KgDQoNCvCfmoAgQm9vc3RlZCBXaGF0bm90IGFwcGxpY2F0aW9uLiBBZnRlciBzaWduaW5nIHVwLCB5b3VyIGFwcGxpY2F0aW9uIHdpbGwgc2hvdyB1cCBmaXJzdCBmb3IgV2hhdG5vdC7CoA0KDQrCoPCfpJcgVGhvdXNhbmRzIG9mIG90aGVyIG9wcG9ydHVuaXRpZXMuIE91ciBwYXJ0bmVycyBpbmNsdWRlIEx5ZnQsIERvb3JEYXNoIGFuZCBEZWxvaXR0ZSwgYW5kIHJhbmdlIGZyb20gc21hbGwgc3RhcnR1cHMgdG8gRm9ydHVuZSA1MDBzLg0KDQrwn5OpIEFwcGxpY2F0aW9ucyBjb21lIHRvIHlvdS4gT3ZlciA1MDBrIHJlY3J1aXRlciBtZXNzYWdlcyBoYXZlIGJlZW4gc2VudCB0byBqb2Igc2Vla2VycyBpbiB0aGUgcGFzdCB5ZWFyLg0KDQpZb3UgYXJlIHJlY2VpdmluZyBlbWFpbCBub3RpZmljYXRpb25zIGZyb20gVW50YXBwZWQuIFtVbnN1YnNjcmliZV0oaHR0cHM6Ly9tYW5hZ2Uua21haWwtbGlzdHMuY29tL3N1YnNjcmlwdGlvbnMvdW5zdWJzY3JpYmU_YT1VYmlycWomYz0wMUo5SDgyVjRYMk41UEZFM0dDREZGMzVBRCZrPTAzYzE3NmRkNDdjNTg1ZjYxZmI3MWE1ZGI2Nzk3MTExJm09UzI2OERIJnI9NjJuQUt3SykuICBJZiB5b3UgbmVlZCBhc3Npc3RhbmNlIG9yIGhhdmUgcXVlc3Rpb25zLCBwbGVhc2UgYXNrIHVzIGF0IFtpbmZvQHVudGFwcGVkLmlvXShtYWlsdG86aW5mb0B1bnRhcHBlZC5pbykNCsKgDQrCqSAyMDIyIFVudGFwcGVkIExhYnMsIEluYy4gODYwNSBTYW50YSBNb25pY2EgQmx2ZC4gU3VpdGUgODQ1NjEgV2VzdCBIb2xseXdvb2QsIENBIDkwMDY5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m named_ents \u001b[38;5;241m=\u001b[39m tagger(text)\n\u001b[0;32m----> 6\u001b[0m maxda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnamed_ents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(maxda[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(named_ents)\n",
      "\u001b[0;31mValueError\u001b[0m: max() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "text = \"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_cmVmPWVtYWlsJnV0bV9zb3VyY2U9V2hhdG5vdCZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9jYW1wYWlnbj1hdHNfaW52aXRlX2Zyb21fb3JnYW5pemF0aW9uJnV0bV9jb250ZW50PWN0YWJ1dHRvbiZlbWFpbD1zdGVwaGVubHVvbmcyNCU0MGdtYWlsLmNvbSZhdHNfYWNjb3VudF9saW5rX3Rva2VuPTljU2JSQTJmMFR2UXdtaHhOVVdBY2JETFE4Q29YWlRuJnN0dWRlbnRfZnVsbF9uYW1lPVRyaStDdW9uZytMdW9uZyZsb2dvX3VybD1odHRwcyUzQSUyRiUyRmp1bXBzdGFydC1zdGF0aWMuczMuYW1hem9uYXdzLmNvbSUyRmJhY2tlbmQlMkZfX3NpemVkX18lMkZvcmdhbml6YXRpb25zJTJGb3JnYW5pemF0aW9uJTJGel8wdjdiOEhTM3F5NHIxY2VMRGVFUS10aHVtYm5haWwtMjAweDIwMC5wbmcmb3JnYW5pemF0aW9uX2lkPXdoYXRub3Qmb3JnYW5pemF0aW9uX25hbWU9V2hhdG5vdCZyb2xlX2lkPTM2YjE1NzQwLThlZTItNGZiMi05MGZiLTc1NWU5YTBjMGI0MCZyb2xlX3R5cGU9Sk9CJnJvbGVfdGl0bGU9U29mdHdhcmUrRW5naW5lZXIrSW50ZXJuJTJDK1N1bW1lcisyMDI1KQ0KDQpGQVE6IFdoYXQgZWxzZSBkbyBJIGdldCBmcm9tIFVudGFwcGVkP8KgDQoNCvCfmoAgQm9vc3RlZCBXaGF0bm90IGFwcGxpY2F0aW9uLiBBZnRlciBzaWduaW5nIHVwLCB5b3VyIGFwcGxpY2F0aW9uIHdpbGwgc2hvdyB1cCBmaXJzdCBmb3IgV2hhdG5vdC7CoA0KDQrCoPCfpJcgVGhvdXNhbmRzIG9mIG90aGVyIG9wcG9ydHVuaXRpZXMuIE91ciBwYXJ0bmVycyBpbmNsdWRlIEx5ZnQsIERvb3JEYXNoIGFuZCBEZWxvaXR0ZSwgYW5kIHJhbmdlIGZyb20gc21hbGwgc3RhcnR1cHMgdG8gRm9ydHVuZSA1MDBzLg0KDQrwn5OpIEFwcGxpY2F0aW9ucyBjb21lIHRvIHlvdS4gT3ZlciA1MDBrIHJlY3J1aXRlciBtZXNzYWdlcyBoYXZlIGJlZW4gc2VudCB0byBqb2Igc2Vla2VycyBpbiB0aGUgcGFzdCB5ZWFyLg0KDQpZb3UgYXJlIHJlY2VpdmluZyBlbWFpbCBub3RpZmljYXRpb25zIGZyb20gVW50YXBwZWQuIFtVbnN1YnNjcmliZV0oaHR0cHM6Ly9tYW5hZ2Uua21haWwtbGlzdHMuY29tL3N1YnNjcmlwdGlvbnMvdW5zdWJzY3JpYmU_YT1VYmlycWomYz0wMUo5SDgyVjRYMk41UEZFM0dDREZGMzVBRCZrPTAzYzE3NmRkNDdjNTg1ZjYxZmI3MWE1ZGI2Nzk3MTExJm09UzI2OERIJnI9NjJuQUt3SykuICBJZiB5b3UgbmVlZCBhc3Npc3RhbmNlIG9yIGhhdmUgcXVlc3Rpb25zLCBwbGVhc2UgYXNrIHVzIGF0IFtpbmZvQHVudGFwcGVkLmlvXShtYWlsdG86aW5mb0B1bnRhcHBlZC5pbykNCsKgDQrCqSAyMDIyIFVudGFwcGVkIExhYnMsIEluYy4gODYwNSBTYW50YSBNb25pY2EgQmx2ZC4gU3VpdGUgODQ1NjEgV2VzdCBIb2xseXdvb2QsIENBIDkwMDY5\"\n",
    "named_ents = tagger(text)\n",
    "maxda = max(named_ents, key=lambda x: x['score'])\n",
    "print(maxda['word'])\n",
    "print(named_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m email_contents \u001b[38;5;241m=\u001b[39m [mailContent \u001b[38;5;28;01mfor\u001b[39;00m _, _, _, mailContent, _ \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Process all email contents in a batch\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m company_names \u001b[38;5;241m=\u001b[39m \u001b[43mget_word_with_max_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail_contents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mailId, mailCategories, mailSubject, mailContent, mailTime \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "Cell \u001b[0;32mIn[78], line 35\u001b[0m, in \u001b[0;36mget_word_with_max_score\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m named_ents \u001b[38;5;241m=\u001b[39m \u001b[43mtagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Process all email contents in batch\u001b[39;00m\n\u001b[1;32m     36\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Each email will have a list of named entities. Extract max score word for each\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:250\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    248\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offset_mapping\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/base.py:1249\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1246\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1247\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1248\u001b[0m     )\n\u001b[0;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:287\u001b[0m, in \u001b[0;36mTokenClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: special_tokens_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m    297\u001b[0m }\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1890\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1888\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1890\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1902\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1904\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# tagger = pipeline(task='ner', aggregation_strategy='max')\n",
    "# def get_word_with_max_score(data):\n",
    "#     if not data:  # Check if the list is empty\n",
    "#         return None\n",
    "#     named_ents = tagger(data)  \n",
    "#     max_item = max(named_ents, key=lambda x: x['score'])\n",
    "#     return max_item['word']\n",
    "\n",
    "# new_json = defaultdict(list)\n",
    "# temp_list = []\n",
    "# for app_status, data in datas.items():\n",
    "#     for email, email_data in data.items():\n",
    "#         for mailId, mailCategories, mailSubject, mailContent, mailTime in email_data:\n",
    "#             mailCompany = get_word_with_max_score(mailContent)\n",
    "        \n",
    "#             new_json[email].append([mailId, mailCategories, mailCompany, mailSubject, mailContent, mailTime])\n",
    "# print(new_json)\n",
    "\n",
    "from transformers import pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the NER model once\n",
    "tagger = pipeline(task='ner', aggregation_strategy='max')\n",
    "\n",
    "def get_word_with_max_score(contents):\n",
    "    \"\"\"\n",
    "    This function processes a batch of email contents and returns a list of the\n",
    "    company name (or the word with the highest NER score) for each email.\n",
    "    \"\"\"\n",
    "    if not contents:\n",
    "        return None\n",
    "    \n",
    "    named_ents = tagger(contents)  # Process all email contents in batch\n",
    "    result = []\n",
    "    \n",
    "    # Each email will have a list of named entities. Extract max score word for each\n",
    "    for ents in named_ents:\n",
    "        if ents:  # Check if there are named entities for this email\n",
    "            max_item = max(ents, key=lambda x: x['score'])\n",
    "            result.append(max_item['word'])\n",
    "        else:\n",
    "            result.append(None)  # No named entities found\n",
    "    return result\n",
    "\n",
    "new_json = defaultdict(list)\n",
    "temp_list = []\n",
    "\n",
    "for app_status, data in datas['app_focused'].items():\n",
    "    email_contents = [mailContent for _, _, _, mailContent, _ in data]\n",
    "    \n",
    "    # Process all email contents in a batch\n",
    "    company_names = get_word_with_max_score(email_contents)\n",
    "\n",
    "    i = 0\n",
    "    for mailId, mailCategories, mailSubject, mailContent, mailTime in email_data:\n",
    "        mailCompany = company_names[i]\n",
    "        i += 1\n",
    "        new_json[email].append([mailId, mailCategories, mailCompany, mailSubject, mailContent, mailTime])\n",
    "\n",
    "print(new_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     max_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(data, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m max_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[43mget_word_with_max_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDear Cuong,Thank you very much for your recent application to Intuit. Your submissionwill be reviewed by our recruiting staff, and we will contact you soon, should we feel that your background meets our current needs.Sincerely,IntuitThis is an automated email response. Please do not reply.**************************************************This message was sent to stephenluong24@gmail.com. If you don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt want to receive these emails from this company in the future, please go to:https://tracking.icims.com/f/a/jYlnqoLuIyiwOPK5NAWJXQ~~/AAIB5gA~/RgRo5a5DP0RLaHR0cHM6Ly9pbnR1aXQuaWNpbXMuY29tL2ljaW1zMi8_cj1DRTRCMjY0MTU2NSZjb250YWN0SWQ9MTA3MjIzMDcmcGlkPTQ5NDU4VwNzcGNCCmb4QykDZxD1GhxSGHN0ZXBoZW5sdW9uZzI0QGdtYWlsLmNvbVgEAAAKKw~~ /n \u001b[39;49m\u001b[38;5;130;43;01m\\u00a9\u001b[39;49;00m\u001b[38;5;124;43m Intuit, Inc.; 7535 Torrey Santa Fe Rd; San Diego, CA 92129; USA/n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 5\u001b[0m, in \u001b[0;36mget_word_with_max_score\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:  \u001b[38;5;66;03m# Check if the list is empty\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m max_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[71], line 5\u001b[0m, in \u001b[0;36mget_word_with_max_score.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:  \u001b[38;5;66;03m# Check if the list is empty\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m max_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(data, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_company_with_regex(content):\n",
    "    # A simple regex that looks for capitalized words or company suffixes\n",
    "    pattern = r'\\b[A-Z][a-z]*\\s(?:Inc|Ltd|Corp|LLC|Group|Technologies)\\b'\n",
    "    match = re.search(pattern, content)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n",
    "print(find_company_with_regex(\"Hi Tri Cuong Luong,Thank you for applying to the Data Science Internship - Summer 2025 at Klaviyo.We received an overwhelming number of qualified applicants and are honored that so many talented candidates (like you!) are interested in working with us. Although your background is impressive, we've decided to move forward with other candidates at this time.We know how hard the job search can be and we thank you for investing the time in applying to Klaviyo. We do hope you'll keep us in mind for future opportunities.Curious to learn more about Klaviyo? Check us out onLinkedIn ( https://www.linkedin.com/company/klaviyo/ ),BuiltIn Boston ( https://www.builtinboston.com/company/klaviyo ) ,Comparably ( https://www.comparably.com/companies/klaviyo ),Glassdoor, ( https://www.glassdoor.com/Overview/Working-at-Klaviyo-EI_IE1169266.11,18.htm ) Instagram ( https://www.instagram.com/lifeatklaviyo/ ) and ourEngineering Blog ( https://klaviyo.tech/ ).Best of luck with your search,Klaviyo Campus Recruiting Team\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
